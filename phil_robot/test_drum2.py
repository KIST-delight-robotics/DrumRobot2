# [main.py ë§¨ ìœ—ë¶€ë¶„]
import os

# 1. CUDA ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œ ê°•ì œ ì§€ì • (ì ¯ìŠ¨ í‘œì¤€ ê²½ë¡œ)
os.environ["PATH"] += os.pathsep + '/usr/local/cuda/bin'
os.environ["LD_LIBRARY_PATH"] = '/usr/local/cuda/lib64' + (os.pathsep + os.environ.get("LD_LIBRARY_PATH", "") if os.environ.get("LD_LIBRARY_PATH") else "")

import torch

# GPUê°€ ì •ë§ ì¸ì‹ë˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ì½”ë“œ (í„°ë¯¸ë„ì— ì¶œë ¥ë¨)
cuda_available = torch.cuda.is_available()
print(f">>> [System] CUDA Available: {cuda_available}")
if cuda_available:
    print(f">>> [System] GPU Device: {torch.cuda.get_device_name(0)}")
else:
    print(">>> [Critical] GPUê°€ ì•„ì§ ì¸ì‹ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. CPUë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
    # ì„ì‹œë¡œ ì‹¤í–‰ì´ë¼ë„ ë˜ê²Œ í•˜ë ¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ (í•˜ì§€ë§Œ ëŠë ¤ì§)
    # DEVICE = "cpu"

# --- ì•„ê¹Œ ê·¸ 'weights_only' íŒ¨ì¹˜ë„ ì´ í™˜ê²½ì— ë‹¤ì‹œ í•„ìš”í•©ë‹ˆë‹¤ ---
_original_load = torch.load
def safe_load(*args, **kwargs):
    if 'weights_only' in kwargs:
        kwargs['weights_only'] = False
    return _original_load(*args, **kwargs)
torch.load = safe_load
print(">>> [System] PyTorch 'weights_only' security check bypassed.")
import sys
import ctypes
import time
import tempfile
import sounddevice as sd
import numpy as np
import ollama
import whisper  # openai-whisper
from TTS.api import TTS
import torchaudio

# ==========================================
# ğŸ”§ [ì‹œìŠ¤í…œ ì„¤ì •] ì ¯ìŠ¨ GPU í™˜ê²½ ìµœì í™”
# ==========================================

# 1. libgomp ê²½ë¡œ ìˆ˜ì • (drum -> drum2)
# TLS ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ë¯¸ë¦¬ ë¡œë“œí•©ë‹ˆë‹¤.
try:
    # ë°•ì‚¬ë‹˜ í˜„ì¬ í™˜ê²½ ì´ë¦„ì´ 'drum2'ì¸ ê²ƒì„ ë°˜ì˜í–ˆìŠµë‹ˆë‹¤.
    ctypes.CDLL("/home/shy/miniforge3/envs/drum2/lib/libgomp.so.1")
    print(">>> [System] libgomp Pre-loaded successfully!")
except OSError:
    try:
        # í˜¹ì‹œ ê²½ë¡œê°€ ë‹¤ë¥¼ê¹Œë´ ì‹œìŠ¤í…œ ê¸°ë³¸ ê²½ë¡œë„ ì‹œë„
        ctypes.CDLL("/usr/lib/aarch64-linux-gnu/libgomp.so.1")
    except:
        pass

# 2. ì˜¤ë””ì˜¤ ë°±ì—”ë“œ 'soundfile' ê°•ì œ ê³ ì •
# torchaudioê°€ ì œë©‹ëŒ€ë¡œ êµ´ì§€ ì•Šê²Œ ë”± ì¡ì•„ë‘¡ë‹ˆë‹¤.
try:
    torchaudio.set_audio_backend("soundfile")
except:
    pass

# ==========================================
# ğŸ¤– [ë¡œë´‡ ì„¤ì •]
# ==========================================
ROBOT_NAME = "phil-bot"      # Ollama ëª¨ë¸ ì´ë¦„
VOICE_REF = "phil_voice1.wav" # ë³µì œí•  ëª©ì†Œë¦¬ íŒŒì¼ (ê°™ì€ í´ë”ì— ìˆì–´ì•¼ í•¨)
SAMPLE_RATE = 16000          
DEVICE = "cuda"              # ğŸ”¥ ìƒë‚¨ìì˜ GPU ëª¨ë“œ

print(f">>> [1/3] ğŸ‘‚ ê·€(Whisper) ì¥ì°© ì¤‘... ({DEVICE})")
# OpenAI Whisper ë¡œë“œ (GPU ê°€ì†)
stt_model = whisper.load_model("small", device=DEVICE)

print(f">>> [2/3] ğŸ‘„ ì…(XTTS) ì¥ì°© ì¤‘... ({DEVICE})")
# XTTS ë¡œë“œ (GPU ê°€ì†)
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(DEVICE)

print(f">>> [3/3] ğŸ¤– {ROBOT_NAME} ê¹¨ì–´ë‚˜ëŠ” ì¤‘...")

def record_audio(duration=5):
    print("\nğŸ¤ ë“£ê³  ìˆì–´ìš”... (ë§ì”€í•˜ì„¸ìš”!)")
    # ì ¯ìŠ¨ ë§ˆì´í¬ ë…¹ìŒ
    audio = sd.rec(int(duration * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=1, dtype='float32')
    sd.wait()
    print("â¹ï¸ ë…¹ìŒ ë!")
    return audio.flatten()

def speak(text):
    if not text: return
    print(f"ğŸ¤– Phil: {text}")
    
    # ì„ì‹œ íŒŒì¼ ìƒì„±
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
        output_path = f.name
        
    # ì•½ê´€ ë™ì˜ ìë™ íŒ¨ìŠ¤
    os.environ["COQUI_TOS_AGREED"] = "1"
    
    # GPUë¡œ ìŒì„± í•©ì„±
    tts.tts_to_file(
        text=text,
        file_path=output_path,
        speaker_wav=VOICE_REF, 
        language="ko"
    )
    
    # ì¬ìƒ (ë¦¬ëˆ…ìŠ¤ aplay ì‚¬ìš©)
    os.system(f"aplay {output_path} > /dev/null 2>&1")
    os.remove(output_path)

# --- ë©”ì¸ ì‹¤í–‰ ë£¨í”„ ---
try:
    speak("ë°•ì‚¬ë‹˜! ì € í•„ì´ì—ìš”. GPUë¡œ ëŒì•„ì˜¤ë‹ˆê¹Œ í˜ì´ ë„˜ì³ìš”!")
    
    while True:
        # ì—”í„° í‚¤ ì…ë ¥ ëŒ€ê¸° (ë§ˆì´í¬ ì¡ìŒ ë°©ì§€)
        input("\n[Enter]ë¥¼ ëˆ„ë¥´ê³  ë§ì”€í•˜ì„¸ìš”...") 
        
        # 1. ë“£ê¸°
        audio_data = record_audio(duration=4) 
        
        # 2. ë°›ì•„ì ê¸° (OpenAI Whisper ë°©ì‹)
        # fp16=Trueë¡œ ì„¤ì •í•˜ì—¬ GPU í…ì„œ ì½”ì–´ë¥¼ ì‚¬ìš© (ì†ë„ í–¥ìƒ)
        result = stt_model.transcribe(audio_data, language="ko", fp16=True)
        user_text = result['text'].strip()
        
        if not user_text:
            print("?? (ì•ˆ ë“¤ë ¤ìš”)")
            continue
            
        print(f"ğŸ‘¤ User: {user_text}")
        
        # ì¢…ë£Œ ëª…ë ¹ì–´
        if "ì˜ ê°€" in user_text or "ì¢…ë£Œ" in user_text:
            speak("ì•ˆë…•íˆ ê³„ì„¸ìš”! ì¿µì¹˜ë”°!")
            break

        # 3. ìƒê°í•˜ê¸° (Ollama)
        # OllamaëŠ” ì•Œì•„ì„œ GPUë¥¼ ì“°ë‹ˆ ê±±ì • ë§ˆì„¸ìš”
        response = ollama.chat(model=ROBOT_NAME, messages=[
            {'role': 'user', 'content': user_text},
        ])
        reply = response['message']['content']

        # 4. ë§í•˜ê¸°
        speak(reply)

except KeyboardInterrupt:
    print("\nì‹œìŠ¤í…œ ì¢…ë£Œ.")
except Exception as e:
    print(f"\nâŒ ì—ëŸ¬ ë°œìƒ: {e}")