import sounddevice as sd
import whisper
import ollama
# TTS ì—”ì§„
from melo_engine import TTS_Engine

# ==========================================
# âš™ï¸ ì„¤ì •ê°’ (Config)
# ==========================================
SAMPLE_RATE = 16000      # Whisper ê¶Œì¥ ìƒ˜í”Œë§ ë ˆì´íŠ¸
RECORD_SECONDS = 5       # í•œ ë²ˆì— ë“¤ì„ ì‹œê°„ (5ì´ˆ)
LLM_MODEL = "phil-bot"     # âš ï¸ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ëª…ìœ¼ë¡œ ë³€ê²½ í•„ìˆ˜

# ==========================================
# ğŸ”§ ë…¹ìŒ í•¨ìˆ˜
# ==========================================
def record_audio():
    """ë§ˆì´í¬ë¡œ ì†Œë¦¬ë¥¼ ë“£ê³  Arrayë¡œ ë°˜í™˜"""
    print(f"\nğŸ¤ ë“£ëŠ” ì¤‘... ({RECORD_SECONDS}ì´ˆ)")
    try:
        # float32ë¡œ ë…¹ìŒ í›„ 1ì°¨ì›ìœ¼ë¡œ í´ì„œ(flatten) ë°˜í™˜
        audio = sd.rec(int(RECORD_SECONDS * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=1, dtype='float32')
        sd.wait()
        return audio.flatten()
        
    except Exception as e:
        print(f"âŒ ë§ˆì´í¬ ë…¹ìŒ ì‹¤íŒ¨: {e}")
        return None

# ==========================================
# ğŸš€ ë©”ì¸ í•¨ìˆ˜
# ==========================================
def main():
    print("========== [AI CONVERSATION MODE] ==========")

    # 1. [ì´ˆê¸°í™”] TTS & STT ë¡œë”©
    # ----------------------------------------------
    tts = TTS_Engine() # TTS ì—”ì§„ ì‹œë™
    
    print("[STT] Whisper ëª¨ë¸ ë¡œë”© ì¤‘... (GPU)")
    # small ëª¨ë¸ ì‚¬ìš©
    stt_model = whisper.load_model("small", device="cuda")
    print("[STT] ì¤€ë¹„ ì™„ë£Œ!")
    
    # ì²« ì¸ì‚¬
    tts.speak("ëŒ€í™” ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ì—”í„° í‚¤ë¥¼ ëˆ„ë¥´ê³  ë§ì”€í•´ ì£¼ì„¸ìš”.")

    # 2. [ë£¨í”„] ëŒ€í™” ë°˜ë³µ
    # ----------------------------------------------
    while True:
        try:
            # --- RESTART ---
            key = input("\nâŒ¨ï¸ [Enter]ë¥¼ ëˆ„ë¥´ë©´ ë“£ìŠµë‹ˆë‹¤ (ì¢…ë£Œ: q) >> ")
            if key.lower() == 'q':
                print("ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            # --- A. ë“£ê¸° (STT) ---
            audio_data = record_audio()
            if audio_data is None: continue
            
            # Whisperë¡œ ë³€í™˜
            print("ğŸ“œ í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘...")
            result = stt_model.transcribe(audio_data, fp16=False, language="ko", initial_prompt="ìê¸°ì†Œê°œ, í•„ë´‡")
            user_text = result['text'].strip()
            
            print(f"ğŸ—£ï¸ ì‚¬ìš©ì: {user_text}")

            if not user_text:
                print("âš ï¸ ì†Œë¦¬ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                continue

            # --- B. ìƒê°í•˜ê¸° (LLM) ---
            print("ğŸ§  ìƒê° ì¤‘...")
            
            # Ollamaì—ê²Œ ì§ˆë¬¸
            response = ollama.chat(model=LLM_MODEL, messages=[
                {'role': 'user', 'content': user_text},
            ])
            ai_response = response['message']['content']

            # --- C. ë§í•˜ê¸° (TTS) ---
            print(f"ğŸ¤– AI: {ai_response}")
            tts.speak(ai_response)

        except KeyboardInterrupt:
            print("\nì‹œìŠ¤í…œ ê°•ì œ ì¢…ë£Œ")
            break
        except Exception as e:
            print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()