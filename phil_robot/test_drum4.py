import sounddevice as sd
import whisper
import ollama
#import json
import numpy as np
import time
# TTS ì—”ì§„
from melo_engine import TTS_Engine

# ==========================================
# âš™ï¸ ì„¤ì •ê°’ (Config)
# ==========================================
SAMPLE_RATE = 16000      # Whisper ê¶Œì¥ ìƒ˜í”Œë§ ë ˆì´íŠ¸
RECORD_SECONDS = 3       # í•œ ë²ˆì— ë“¤ì„ ì‹œê°„ (3ì´ˆ)
LLM_MODEL = "phil-speech"     # âš ï¸ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ëª…ìœ¼ë¡œ ë³€ê²½ í•„ìˆ˜

# ==========================================
# ğŸ”§ ë…¹ìŒ í•¨ìˆ˜
# ==========================================
def record_audio():
    """ë§ˆì´í¬ë¡œ ì†Œë¦¬ë¥¼ ë“£ê³  Arrayë¡œ ë°˜í™˜"""
    print(f"\nğŸ¤ ë“£ëŠ” ì¤‘... ({RECORD_SECONDS}ì´ˆ)")
    try:
        # float32ë¡œ ë…¹ìŒ í›„ 1ì°¨ì›ìœ¼ë¡œ í´ì„œ(flatten) ë°˜í™˜
        audio = sd.rec(int(RECORD_SECONDS * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=1, dtype='float32')
        sd.wait()
        return audio.flatten()
        
    except Exception as e:
        print(f"âŒ ë§ˆì´í¬ ë…¹ìŒ ì‹¤íŒ¨: {e}")
        return None

# ==========================================
# ğŸš€ ë©”ì¸ í•¨ìˆ˜
# ==========================================
def main():
    print("========== [AI CONVERSATION MODE] ==========")

    # 1. [ì´ˆê¸°í™”] TTS & STT ë¡œë”©
    # ----------------------------------------------
    tts = TTS_Engine() # TTS ì—”ì§„ ì‹œë™
    
    print("[STT] Whisper ëª¨ë¸ ë¡œë”© ì¤‘... (GPU)")
    # small ëª¨ë¸ ì‚¬ìš©
    stt_model = whisper.load_model("small", device="cuda")
    print("[STT] ì¤€ë¹„ ì™„ë£Œ!")
    
    # ğŸ”¥ [ì¤‘ìš”] ëª¨ë¸ ì›Œë°ì—… (Warm-up)
    # ê°€ì§œ(0ìœ¼ë¡œ ì±„ì›Œì§„) ì˜¤ë””ì˜¤ë¥¼ í•œë²ˆ ëŒë ¤ì„œ GPU ì´ˆê¸°í™” ë¬¸ì œë¥¼ ë°©ì§€í•¨
    print("ğŸ”¥ ëª¨ë¸ ì˜ˆì—´ ì¤‘... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)")
    try:
        dummy_audio = np.zeros(16000, dtype=np.float32) # 2ì´ˆì§œë¦¬ ë¬´ìŒ
        stt_model.transcribe(dummy_audio, fp16=True)
    except:
        pass # ì›Œë°ì—… ì—ëŸ¬ëŠ” ë¬´ì‹œ



    # ğŸ“Œ [ìˆ˜ì • 1] ëŒ€í™” ê¸°ì–µì¥ì¹˜(History) ì´ˆê¸°í™”
    # ---------------------------------------------------------
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ëŠ” Modelfileì— ìˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„  ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì‹œì‘í•´ë„ ë©ë‹ˆë‹¤.
    history = [] 
    # ---------------------------------------------------------


    # ì²« ì¸ì‚¬
    tts.speak("ëŒ€í™” ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ì—”í„° í‚¤ë¥¼ ëˆ„ë¥´ê³  ë§ì”€í•´ ì£¼ì„¸ìš”.")

    # 2. [ë£¨í”„] ëŒ€í™” ë°˜ë³µ
    # ----------------------------------------------
    while True:
        try:
            # --- RESTART ---
            key = input("\nâŒ¨ï¸ [Enter]ë¥¼ ëˆ„ë¥´ë©´ ë“£ìŠµë‹ˆë‹¤ (ì¢…ë£Œ: q) >> ")
            if key.lower() == 'q':
                print("ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            # --- A. ë“£ê¸° (STT) ---
            audio_data = record_audio()
            if audio_data is None: continue
            
            stt_start_time = time.time()

            # Whisperë¡œ ë³€í™˜
            print("ğŸ“œ í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘...")
            result = stt_model.transcribe(audio_data, fp16=True, language="ko", initial_prompt="ìê¸°ì†Œê°œ, í•„ë´‡")
            user_text = result['text'].strip()
            
            print(f"ğŸ—£ï¸ ì‚¬ìš©ì: {user_text}")
            
            stt_end_time = time.time()
            print(f"â±ï¸ STT ì²˜ë¦¬ ì‹œê°„: {stt_end_time - stt_start_time:.2f}ì´ˆ")

            if not user_text:
                print("âš ï¸ ì†Œë¦¬ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                continue



            # ğŸ“Œ [ìˆ˜ì • 2] ì‚¬ìš©ì ë§ì„ ê¸°ì–µì¥ì¹˜ì— ì €ì¥ + ì˜¤ë˜ëœ ê¸°ì–µ ì‚­ì œ
            # ---------------------------------------------------------
            history.append({'role': 'user', 'content': user_text})
            
            # [Jetson ë³´í˜¸] ê¸°ì–µì´ ë„ˆë¬´ ê¸¸ì–´ì§€ë©´(10í„´ ì´ìƒ) ì•ë¶€ë¶„ ì‚­ì œ (Sliding Window)
            if len(history) > 10:
                history = history[-10:] 
            # ---------------------------------------------------------


            # --- B. ìƒê°í•˜ê¸° (LLM) ---
            print("ğŸ§  ìƒê° ì¤‘...")
            
            llm_start_time = time.time()


            # ğŸ“Œ [ìˆ˜ì • 3] messagesì— ë°©ê¸ˆ í•œ ë§ì´ ì•„ë‹ˆë¼ 'history' ì „ì²´ë¥¼ ë„£ìŒ
            # Ollamaì—ê²Œ ì§ˆë¬¸
            response = ollama.chat(
                model=LLM_MODEL,
                messages=history,
                #format='json'
            )
            
            # JSON íŒŒì‹±
            ai_raw_json = response['message']['content'] # ì›ë³¸ JSON ë¬¸ìì—´
            #ai_data = json.loads(ai_raw_json)
            #ai_msg = ai_data.get("response", "ëª¨ë¥´ê² ì–´ìš”")


            # ğŸ“Œ [ìˆ˜ì • 4] ë¡œë´‡ì˜ ëŒ€ë‹µë„ ê¸°ì–µì¥ì¹˜ì— ì €ì¥í•´ì•¼ ë‹¤ìŒ í„´ì— ê¸°ì–µí•¨
            # ---------------------------------------------------------
            # ì¤‘ìš”: 'ai_msg'(í…ìŠ¤íŠ¸)ê°€ ì•„ë‹ˆë¼ 'ai_raw_json'(JSONí˜•ì‹)ì„ ì €ì¥í•´ì•¼ 
            # ë¡œë´‡ì´ ë‹¤ìŒë²ˆì—ë„ JSON í¬ë§·ì„ ìœ ì§€í•˜ë ¤ê³  ë…¸ë ¥í•©ë‹ˆë‹¤.
            history.append({'role': 'assistant', 'content': ai_raw_json})
            # ---------------------------------------------------------


            llm_end_time = time.time()
            print(f"â±ï¸ LLM ì²˜ë¦¬ ì‹œê°„: {llm_end_time - llm_start_time:.2f}ì´ˆ")
            
            # --- C. ë§í•˜ê¸° (TTS) ---
            #print(f"ğŸ¤– AI: {ai_msg}")
            print(f"ğŸ¤– AI (ì›ë³¸ JSON): {ai_raw_json}")

            #tts.speak(ai_msg)
            tts.speak(ai_raw_json)

        except KeyboardInterrupt:
            print("\nì‹œìŠ¤í…œ ê°•ì œ ì¢…ë£Œ")
            break
        except Exception as e:
            print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()