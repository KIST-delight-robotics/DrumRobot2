import sounddevice as sd
import whisper
import ollama
import numpy as np
import time
import threading
import queue
from collections import deque
from melo_engine import TTS_Engine

# ==========================================
# âš™ï¸ ì„¤ì •ê°’
# ==========================================
SAMPLE_RATE = 16000
LLM_MODEL = "phil-speech"
WAKE_WORDS = ["í•„", "í•„ë´‡", "í”¼ë¦¬", "ì•ˆë…•", "ë¡œë´‡", "ì¼ë´‡", "ë¹Œë´‡", "ì‚˜ë´‡", "Phil", "í•„ë³´ì‚¬"]

START_THRESHOLD = 15
STOP_THRESHOLD = 8
PRE_RECORD_SECONDS = 0.5
CONVERSATION_TIMEOUT = 20
TRASH_TEXTS = ["MBC", "ë‰´ìŠ¤", "êµ¬ë…", "ì¢‹ì•„ìš”", "ì‹œì²­", "ê°ì‚¬", "ì—¬ëŸ¬ë¶„"]

# ==========================================
# ğŸš¦ ì „ì—­ ë³€ìˆ˜ (ìŠ¤ë ˆë“œ ê°„ í†µì‹ ìš©)
# ==========================================
audio_queue = queue.Queue()  # ê·€ê°€ ë“¤ì€ ê±¸ ë‡Œë¡œ ë³´ë‚´ëŠ” íƒë°° ìƒì
is_speaking = False          # "ì§€ê¸ˆ ë§í•˜ëŠ” ì¤‘ì´ë‹ˆ?" (Trueë©´ ë“£ê¸° ì¤‘ë‹¨)
is_running = True            # í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹ í˜¸

# ==========================================
# ğŸ‘‚ [ìŠ¤ë ˆë“œ 1] ê·€ (Listening Thread)
# ==========================================
def listener_thread_func():
    global is_speaking, is_running
    
    print("ğŸ‘‚ [Thread] ê·€ê°€ ì—´ë ¸ìŠµë‹ˆë‹¤ (ë°±ê·¸ë¼ìš´ë“œ ê°ì§€ ì‹œì‘)")
    
    pre_buffer_len = int(PRE_RECORD_SECONDS / 0.1)
    pre_buffer = deque(maxlen=pre_buffer_len)
    
    # ì—¬ê¸°ì„œ ìŠ¤íŠ¸ë¦¼ì„ í•œ ë²ˆ ì—´ì–´ì„œ í”„ë¡œê·¸ë¨ ëë‚  ë•Œê¹Œì§€ ì ˆëŒ€ ë‹«ì§€ ì•ŠìŒ
    with sd.InputStream(samplerate=SAMPLE_RATE, channels=1) as stream:
        while is_running:
            try:
                # 1. 0.1ì´ˆì”© ì½ìœ¼ë©´ì„œ 'í˜¸ì¶œì–´' ëŒ€ê¸°
                indata, _ = stream.read(1600)
                pre_buffer.append(indata)
                volume = np.linalg.norm(indata) * 10
                
                # ğŸš¨ í•µì‹¬: ë¡œë´‡ì´ ë§í•˜ê³  ìˆì„ ë•ŒëŠ” ë“£ì§€ ì•ŠìŒ (Echo ë°©ì§€)
                if is_speaking:
                    sd.sleep(100) # CPU ë‚­ë¹„ ë°©ì§€
                    continue

                # 2. ì†Œë¦¬ê°€ ê°ì§€ë˜ë©´?
                if volume > START_THRESHOLD:
                    print(f"\nâš¡ ì†Œë¦¬ ê°ì§€ (Vol: {volume:.1f}) -> ë…¹ìŒ ì‹œì‘")
                    
                    # --- ìŠ¤ë§ˆíŠ¸ ë…¹ìŒ ë¡œì§ (í•¨ìˆ˜ ì•ˆ ì“°ê³  í’€ì–´ì„œ ì‘ì„±) ---
                    recorded_frames = list(pre_buffer)
                    silent_chunks = 0
                    max_silent = 12 # 1.2ì´ˆ
                    
                    while is_running and not is_speaking: # ë§í•˜ê¸° ì‹œì‘í•˜ë©´ ì¦‰ì‹œ ì¤‘ë‹¨
                        data, _ = stream.read(1600)
                        recorded_frames.append(data)
                        vol = np.linalg.norm(data) * 10
                        
                        if vol > STOP_THRESHOLD: silent_chunks = 0
                        else: silent_chunks += 1
                        
                        if silent_chunks > max_silent: break # ë§ ëë‚¨
                        if len(recorded_frames) > 100: break # 10ì´ˆ ì´ˆê³¼
                    
                    # 3. ë‹¤ ë“¤ì—ˆìœ¼ë©´ í(Queue)ì— ë˜ì§
                    if len(recorded_frames) * 0.1 > 1.0: # 1ì´ˆ ì´ìƒë§Œ
                        final_audio = np.concatenate(recorded_frames).flatten().astype(np.float32)
                        audio_queue.put(final_audio)
                        print("ğŸ“¦ ì˜¤ë””ì˜¤ ë°°ì†¡ ì™„ë£Œ (Queue)")
                    else:
                        print("ğŸ§¹ ë„ˆë¬´ ì§§ì•„ì„œ ë²„ë¦¼")

            except Exception as e:
                print(f"âŒ ê·€ ìŠ¤ë ˆë“œ ì—ëŸ¬: {e}")
                time.sleep(1)

# ==========================================
# ğŸ§  [ë©”ì¸ ìŠ¤ë ˆë“œ] ë‡Œ & ì… (Main Logic)
# ==========================================
def main():
    global is_speaking, is_running
    print("========== [AI THREADED MODE] ==========")

    tts = TTS_Engine()
    print("[STT] Whisper ë¡œë”© ì¤‘...")
    stt_model = whisper.load_model("small", device="cuda")
    
    # ì›Œë°ì—…
    try: stt_model.transcribe(np.zeros(16000, dtype=np.float32), fp16=True)
    except: pass

    # ğŸ§µ ìŠ¤ë ˆë“œ ì‹œì‘ (ê·€ë¥¼ ë…ë¦½ì‹œí‚´)
    listener = threading.Thread(target=listener_thread_func, daemon=True)
    listener.start()

    history = []
    is_active_mode = False
    last_active_time = 0

    tts.speak("ì¤€ë¹„ ì™„ë£Œ.")

    while is_running:
        try:
            # 1. íì—ì„œ ì˜¤ë””ì˜¤ê°€ ì˜¬ ë•Œê¹Œì§€ ëŒ€ê¸° (Blocking)
            # ê·€ ìŠ¤ë ˆë“œê°€ ë­”ê°€ë¥¼ ë“£ê³  íì— ë„£ìœ¼ë©´ ì—¬ê¸°ì„œ ê¹¨ì–´ë‚¨
            try:
                audio_data = audio_queue.get(timeout=1) # 1ì´ˆë§ˆë‹¤ ì²´í¬
            except queue.Empty:
                continue # ì˜¤ë””ì˜¤ ì—†ìœ¼ë©´ ê³„ì† ëŒ€ê¸°

            # 2. STT ë³€í™˜ (ë©”ì¸ ìŠ¤ë ˆë“œê°€ ë‹´ë‹¹)
            print("ğŸ“œ ë³€í™˜ ì¤‘...", end=" ")
            result = stt_model.transcribe(audio_data, fp16=True, language="ko", initial_prompt="ì•ˆë…•í•˜ì„¸ìš” í•„ë´‡ì…ë‹ˆë‹¤.")
            user_text = result['text'].strip()
            print(f"-> [{user_text}]")

            # ìœ íš¨ì„± ê²€ì‚¬
            if len(user_text) < 2: continue
            trash_found = False
            for trash in TRASH_TEXTS:
                if trash in user_text: trash_found = True
            if trash_found: continue

            # 3. ëŒ€í™” ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼)
            current_time = time.time()
            
            if is_active_mode:
                if current_time - last_active_time > CONVERSATION_TIMEOUT:
                    print("ğŸ’¤ ëŒ€ê¸° ëª¨ë“œ ì „í™˜")
                    is_active_mode = False
            
            if not is_active_mode:
                is_wake_up = False
                for word in WAKE_WORDS:
                    if word in user_text:
                        is_wake_up = True
                        break
                if is_wake_up:
                    print("âœ… í˜¸ì¶œì–´ ê°ì§€!")
                    is_active_mode = True
                    
                    # ğŸš¨ ë§í•˜ê¸° ì‹œì‘ -> ê·€ ë§‰ê¸°
                    is_speaking = True 
                    tts.speak("ë„¤?")
                    is_speaking = False # ë‹¤ ë§í–ˆìœ¼ë©´ ê·€ ì—´ê¸°
                    
                    last_active_time = time.time()
                    if len(user_text) < 5: continue
                else:
                    print("ğŸ”‡ ë¬´ì‹œí•¨")
                    continue

            start_time = time.time()
            # 4. LLM ìƒê°
            last_active_time = time.time()
            history.append({'role': 'user', 'content': user_text})
            if len(history) > 10: history = history[-10:]

            print("ğŸ§  ìƒê° ì¤‘...")
            response = ollama.chat(model=LLM_MODEL, messages=history)
            ai_msg = response['message']['content']
            print(f"ğŸ¤– AI: {ai_msg}")

            time_taken = time.time() - start_time
            print(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {time_taken:.2f}ì´ˆ")
            # 5. ë§í•˜ê¸° (ì… ì—´ê¸°)
            # ğŸš¨ í•µì‹¬: ë§í•˜ëŠ” ë™ì•ˆ is_speaking = Trueë¡œ ë§Œë“¤ì–´ì„œ ê·€ ìŠ¤ë ˆë“œë¥¼ ë©ˆì¶¤
            is_speaking = True
            tts.speak(ai_msg)
            is_speaking = False # ë§ ëë‚˜ë©´ ë‹¤ì‹œ ë“£ê¸° ì‹œì‘
            
            history.append({'role': 'assistant', 'content': ai_msg})

        except KeyboardInterrupt:
            print("\nì‹œìŠ¤í…œ ì¢…ë£Œ ì¤‘...")
            is_running = False
            break
        except Exception as e:
            print(f"âŒ ë©”ì¸ ì—ëŸ¬: {e}")

if __name__ == "__main__":
    main()